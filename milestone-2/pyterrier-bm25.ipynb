{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c3da078-f7fc-4d37-904c-532bb26d4321",
   "metadata": {},
   "source": [
    "# BM25 Retrieval with PyTerrier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66fd2911-c97a-4f91-af28-8c7e381573b6",
   "metadata": {},
   "source": [
    "### Step 1: Import everything and load variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ae3c54f-aba1-45bf-b074-e78a99f6405f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start PyTerrier with version=5.7, helper_version=0.0.7, no_download=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.9.2 has loaded Terrier 5.7 (built by craigm on 2022-11-10 18:30) and terrier-helper 0.0.7\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will use a small hardcoded example located in ir-anthology-dataset.\n",
      "The output directory is /tmp/\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "import pandas as pd\n",
    "\n",
    "# We use three methods from the tira third_party_integrations that help to mitigate common pitfalls:\n",
    "# - ensure_pyterrier_is_loaded:\n",
    "#    loads PyTerrier without internet connection\n",
    "#     (in TIRA, retrieval approaches have no access to the internet to improve reproducibility)\n",
    "#\n",
    "# - get_input_directory_and_output_directory:\n",
    "#   Your software is expected to read the data from an input directory and write the results (i.e., the run file) to an output directory.\n",
    "#   Both input and output directories are passes as arguments when the software is executed within TIRA,\n",
    "#   so this command ensures that you can run the same notebook for development as in TIRA by\n",
    "#   returning the passed input directory (that might be mounted) if the software is not executed in TIRA.\n",
    "#\n",
    "# - persist_and_normalize_run:\n",
    "#   Writing run files can come with some non-obvious edge cases (e.g., score ties).\n",
    "#   This method takes care of some frequent of those edge cases.\n",
    "#\n",
    "# You do not have to use any of those methods, in the end it is only \"generate an output from an input\".\n",
    "# We are of course also happy for pull requests that help to improve the handling of frequently used patterns.\n",
    "# Please find the documentation here: https://github.com/tira-io/tira/blob/main/python-client/tira/third_party_integrations.py\n",
    "#\n",
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, get_input_directory_and_output_directory, persist_and_normalize_run\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "ensure_pyterrier_is_loaded()\n",
    "input_directory, output_directory = get_input_directory_and_output_directory('ir-anthology-dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f2a2aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input directory contains the following files:\n",
      "\n",
      "total 111M\n",
      "-rw-r--r-- 1 root root 111M Apr 30 13:09 documents.jsonl\n",
      "-rw-r--r-- 1 root root   73 Apr 30 13:09 metadata.json\n",
      "-rw-r--r-- 1 root root 1.8K Apr 30 13:09 queries.jsonl\n",
      "-rw-r--r-- 1 root root 2.3K Apr 30 13:09 queries.xml\n"
     ]
    }
   ],
   "source": [
    "print('The input directory contains the following files:\\n')\n",
    "!ls -lh {input_directory}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c563b0e-97ac-44a2-ba2f-18858f1506bb",
   "metadata": {},
   "source": [
    "### Step 2: Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e35230af-66ec-4607-a97b-127bd890fa59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Load the data.\n"
     ]
    }
   ],
   "source": [
    "print('Step 2: Load the data.')\n",
    "\n",
    "queries = pt.io.read_topics(input_directory + '/queries.xml', format='trecxml')\n",
    "\n",
    "documents = [json.loads(i) for i in open(input_directory + '/documents.jsonl', 'r')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7adc86e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We look at the first document:\n",
      "\n",
      "{'docno': '2019.sigirconf_workshop-2019birndl.0', 'text': 'CEUR Workshop Proceedings 2414 CEUR-WS.org 2019 http://ceur-ws.org/Vol-2414 urn:nbn:de:0074-2414-3 https://dblp.org/rec/conf/sigir/2019birndl.bib dblp computer science bibliography, https://dblp.org DBLP:conf/sigir/2019birndl proceedings Proceedings of the 4th Joint Workshop on Bibliometric-enhanced Information Retrieval and Natural Language Processing for Digital Libraries (BIRNDL 2019) co-located with the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2019), Paris, France, July 25, 2019 Muthu Kumar Chandrasekaran Philipp Mayr SIGIR 1581522299.0  Proceedings of the 4th Joint Workshop on Bibliometric-enhanced Information Retrieval and Natural Language Processing for Digital Libraries (BIRNDL 2019) co-located with the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2019), Paris, France, July 25, 2019 ', 'original_document': {'doc_id': '2019.sigirconf_workshop-2019birndl.0', 'text': 'CEUR Workshop Proceedings 2414 CEUR-WS.org 2019 http://ceur-ws.org/Vol-2414 urn:nbn:de:0074-2414-3 https://dblp.org/rec/conf/sigir/2019birndl.bib dblp computer science bibliography, https://dblp.org DBLP:conf/sigir/2019birndl proceedings Proceedings of the 4th Joint Workshop on Bibliometric-enhanced Information Retrieval and Natural Language Processing for Digital Libraries (BIRNDL 2019) co-located with the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2019), Paris, France, July 25, 2019 Muthu Kumar Chandrasekaran Philipp Mayr SIGIR 1581522299.0  Proceedings of the 4th Joint Workshop on Bibliometric-enhanced Information Retrieval and Natural Language Processing for Digital Libraries (BIRNDL 2019) co-located with the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2019), Paris, France, July 25, 2019 '}}\n"
     ]
    }
   ],
   "source": [
    "print('We look at the first document:\\n')\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdafebd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We look at the first query:\n",
      "\n",
      "{'qid': '1', 'query': ' fake news detection'}\n"
     ]
    }
   ],
   "source": [
    "print('We look at the first query:\\n')\n",
    "print(queries.iloc[0].to_dict())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72655916-07fe-4c58-82c1-2f9f93381e7f",
   "metadata": {},
   "source": [
    "### Step 3: Create the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05ce062d-25e4-4c61-b6ce-9431b9f2bbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Create the Index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 53673/53673 [00:17<00:00, 2993.66it/s]\n"
     ]
    }
   ],
   "source": [
    "print('Step 3: Create the Index.')\n",
    "\n",
    "!rm -Rf ./index\n",
    "iter_indexer = pt.IterDictIndexer(\"./index\", meta={'docno' : 100})\n",
    "index_ref = iter_indexer.index(tqdm(documents))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "806c4638-ccee-4470-a74c-2a85d9ee2cfc",
   "metadata": {},
   "source": [
    "### Step 4: Create Retrieval Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "642259bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = pt.BatchRetrieve(index_ref, wmodel=\"BM25\", verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cb6607b",
   "metadata": {},
   "source": [
    "### Step 5: Create the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a191f396-e896-4792-afaf-574e452640f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: Create Run.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  4.69q/s]\n"
     ]
    }
   ],
   "source": [
    "print('Step 5: Create Run.')\n",
    "\n",
    "run = bm25(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0e07fca-de98-4de2-b6a7-abfd516c652c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We look at the first 10 results of the run:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14643</td>\n",
       "      <td>2019.wsdm_conference-2019.115</td>\n",
       "      <td>0</td>\n",
       "      <td>27.200501</td>\n",
       "      <td>fake news detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>33491</td>\n",
       "      <td>2018.wwwconf_conference-2018c.140</td>\n",
       "      <td>1</td>\n",
       "      <td>26.183819</td>\n",
       "      <td>fake news detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13148</td>\n",
       "      <td>2020.clef_conference-2020w.200</td>\n",
       "      <td>2</td>\n",
       "      <td>24.150446</td>\n",
       "      <td>fake news detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>13000</td>\n",
       "      <td>2020.clef_conference-2020w.52</td>\n",
       "      <td>3</td>\n",
       "      <td>23.678194</td>\n",
       "      <td>fake news detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13059</td>\n",
       "      <td>2020.clef_conference-2020w.111</td>\n",
       "      <td>4</td>\n",
       "      <td>23.382961</td>\n",
       "      <td>fake news detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>8166</td>\n",
       "      <td>2018.sigirconf_conference-2018.30</td>\n",
       "      <td>5</td>\n",
       "      <td>23.355508</td>\n",
       "      <td>fake news detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>13022</td>\n",
       "      <td>2020.clef_conference-2020w.74</td>\n",
       "      <td>6</td>\n",
       "      <td>23.279387</td>\n",
       "      <td>fake news detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>12972</td>\n",
       "      <td>2020.clef_conference-2020w.24</td>\n",
       "      <td>7</td>\n",
       "      <td>23.100486</td>\n",
       "      <td>fake news detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>13002</td>\n",
       "      <td>2020.clef_conference-2020w.54</td>\n",
       "      <td>8</td>\n",
       "      <td>22.934617</td>\n",
       "      <td>fake news detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>13117</td>\n",
       "      <td>2020.clef_conference-2020w.169</td>\n",
       "      <td>9</td>\n",
       "      <td>22.790468</td>\n",
       "      <td>fake news detection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid  docid                              docno  rank      score  \\\n",
       "0   1  14643      2019.wsdm_conference-2019.115     0  27.200501   \n",
       "1   1  33491  2018.wwwconf_conference-2018c.140     1  26.183819   \n",
       "2   1  13148     2020.clef_conference-2020w.200     2  24.150446   \n",
       "3   1  13000      2020.clef_conference-2020w.52     3  23.678194   \n",
       "4   1  13059     2020.clef_conference-2020w.111     4  23.382961   \n",
       "5   1   8166  2018.sigirconf_conference-2018.30     5  23.355508   \n",
       "6   1  13022      2020.clef_conference-2020w.74     6  23.279387   \n",
       "7   1  12972      2020.clef_conference-2020w.24     7  23.100486   \n",
       "8   1  13002      2020.clef_conference-2020w.54     8  22.934617   \n",
       "9   1  13117     2020.clef_conference-2020w.169     9  22.790468   \n",
       "\n",
       "                  query  \n",
       "0   fake news detection  \n",
       "1   fake news detection  \n",
       "2   fake news detection  \n",
       "3   fake news detection  \n",
       "4   fake news detection  \n",
       "5   fake news detection  \n",
       "6   fake news detection  \n",
       "7   fake news detection  \n",
       "8   fake news detection  \n",
       "9   fake news detection  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('We look at the first 10 results of the run:\\n')\n",
    "run.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28c40a2e-0f96-4ae8-aa5e-55a5e7ef9dee",
   "metadata": {},
   "source": [
    "### Step 6: Persist Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12e5bb42-ed1f-41ba-b7a5-cb43ebca96f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: Persist Run.\n",
      "Done :)\n"
     ]
    }
   ],
   "source": [
    "print('Step 6: Persist Run.')\n",
    "\n",
    "persist_and_normalize_run(run, output_file=output_directory, system_name='BM25', depth=1000)\n",
    "\n",
    "print('Done :)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e74a3eaf",
   "metadata": {},
   "source": [
    "# Reflections\n",
    "\n",
    "## Iris\n",
    "\n",
    "## Yannick\n",
    "\n",
    "The first steps of the second milestone were fairly straightforward, and we managed to generate the `run.txt` and `run.html` files fairly quickly. However, some of the steps were kind of unclear after that, and after asking in the support forum we eventually got the task updated to be a bit more clear. However, since we had already started the milestone and some of the steps had now changed, we had to go back and re-do some of the steps which was a bit confusing. In the end, once we understood the steps of the assigment properly we were able to create the binary relevance assessments relatively quickly and the rest of the steps went more or less as planned.\n",
    "\n",
    "## Justin\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
